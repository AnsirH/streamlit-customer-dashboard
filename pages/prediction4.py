import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from pathlib import Path
import uuid
import sys

# ê²½ë¡œ ì„¤ì •
ROOT = Path(__file__).resolve().parent.parent
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

from models.churn_model import load_xgboost_model2, ChurnPredictor2

# ìœ„í—˜êµ° ë¶„ë¥˜ í•¨ìˆ˜
def classify_risk(prob):
    if prob >= 0.9:
        return "ì´ˆê³ ìœ„í—˜êµ°"
    elif prob >= 0.7:
        return "ê³ ìœ„í—˜êµ°"
    elif prob >= 0.5:
        return "ì£¼ì˜ë‹¨ê³„"
    elif prob >= 0.3:
        return "ê´€ì°°ë‹¨ê³„"
    else:
        return "ë¶„ë¥˜ì œì™¸"

# ì¸ì½”ë”©ëœ ë²”ì£¼í˜•ì„ ë³µì›í•˜ê³  í•œê¸€ ì»¬ëŸ¼ ì ìš©
def reverse_one_hot_columns(df_encoded):
    reverse_map = {
        "PreferredLoginDevice": "ì„ í˜¸ ë¡œê·¸ì¸ ê¸°ê¸°",
        "PreferredPaymentMode": "ì„ í˜¸ ê²°ì œ ë°©ì‹",
        "Gender": "ì„±ë³„",
        "PreferedOrderCat": "ì„ í˜¸ ì£¼ë¬¸ ì¹´í…Œê³ ë¦¬",
        "MaritalStatus": "ê²°í˜¼ ì—¬ë¶€"
    }

    recovered = pd.DataFrame()

    for prefix_en, label_kr in reverse_map.items():
        matched = df_encoded.filter(like=prefix_en + "_")
        recovered[label_kr] = matched.idxmax(axis=1).str.replace(prefix_en + "_", "")

    numeric_features = [
        'Tenure', 'CityTier', 'WarehouseToHome', 'HourSpendOnApp',
        'NumberOfDeviceRegistered', 'SatisfactionScore', 'NumberOfAddress',
        'Complain', 'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount',
        'DaySinceLastOrder', 'CashbackAmount'
    ]
    numeric_labels = [
        "ì´ìš© ê¸°ê°„", "ê±°ì£¼ ë„ì‹œ ë“±ê¸‰", "ì°½ê³ -ì§‘ ê±°ë¦¬", "ì•± ì‚¬ìš© ì‹œê°„",
        "ë“±ë¡ëœ ê¸°ê¸° ìˆ˜", "ë§Œì¡±ë„ ì ìˆ˜", "ë°°ì†¡ì§€ ë“±ë¡ ìˆ˜",
        "ë¶ˆë§Œ ì œê¸° ì—¬ë¶€", "ì£¼ë¬¸ê¸ˆì•¡ ìƒìŠ¹ë¥ ", "ì¿ í° ì‚¬ìš© íšŸìˆ˜", "ì£¼ë¬¸ íšŸìˆ˜",
        "ë§ˆì§€ë§‰ ì£¼ë¬¸ í›„ ê²½ê³¼ì¼", "ìºì‹œë°± ê¸ˆì•¡"
    ]
    for en, kr in zip(numeric_features, numeric_labels):
        if en in df_encoded.columns:
            recovered[kr] = df_encoded[en]

    return recovered[numeric_labels + list(reverse_map.values())]

# Streamlit ì•± ì‹œì‘
st.set_page_config(page_title="ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ì‹œìŠ¤í…œ", layout="wide")
st.title("ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")

st.subheader("ğŸ“ ë°ì´í„° ì…ë ¥")
uploaded_file = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.success(f"âœ… {df.shape[0]}ëª…ì˜ ê³ ê° ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

    df["ê³ ê°ID"] = [str(uuid.uuid4())[:8] for _ in range(len(df))]

    model = load_xgboost_model2()
    predictor = ChurnPredictor2(external_model=model)
    model_features = predictor.model.get_booster().feature_names

    df_encoded = pd.get_dummies(df)
    for col in model_features:
        if col not in df_encoded.columns:
            df_encoded[col] = 0
    df_encoded = df_encoded[model_features]

    _, y_proba = predictor.predict(df_encoded)
    df["ì´íƒˆí™•ë¥ "] = y_proba
    df["ìœ„í—˜êµ°"] = df["ì´íƒˆí™•ë¥ "].apply(classify_risk)

    # ìœ„í—˜êµ°ë³„ ê³ ê° ID (ìƒìœ„ 10ê°œì”©)
    st.subheader("ğŸ“Œ ìœ„í—˜êµ°ë³„ ê³ ê° ID (ìƒìœ„ 10ê°œ)")
    for group in ["ì´ˆê³ ìœ„í—˜êµ°", "ê³ ìœ„í—˜êµ°", "ì£¼ì˜ë‹¨ê³„", "ê´€ì°°ë‹¨ê³„"]:
        st.markdown(f"**{group}**")
        top_ids = df[df["ìœ„í—˜êµ°"] == group].nlargest(10, "ì´íƒˆí™•ë¥ ")["ê³ ê°ID"].tolist()
        st.write(top_ids)

    st.success("âœ… ê³ ê° ID ë¶€ì—¬ ë° êµ°ë³„ ë¶„ë¥˜ê¹Œì§€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")