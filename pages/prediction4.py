import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from pathlib import Path
import uuid
import sys

# ê²½ë¡œ ì„¤ì •
ROOT = Path(__file__).resolve().parent.parent
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

from models.churn_model import load_xgboost_model2, ChurnPredictor2

# í•¨ìˆ˜: ìœ„í—˜êµ° ë¶„ë¥˜
def classify_risk(prob):
    if prob >= 0.9:
        return "ì´ˆê³ ìœ„í—˜êµ°"
    elif prob >= 0.7:
        return "ê³ ìœ„í—˜êµ°"
    elif prob >= 0.5:
        return "ì£¼ì˜ë‹¨ê³„"
    else:
        return "ê´€ì°°ë‹¨ê³„"

st.set_page_config(page_title="ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ì‹œìŠ¤í…œ", layout="wide")
st.title("ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")

st.subheader("ğŸ“ ë°ì´í„° ì…ë ¥")
uploaded_file = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.success(f"âœ… {df.shape[0]}ëª…ì˜ ê³ ê° ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

    model = load_xgboost_model2()
    predictor = ChurnPredictor2(external_model=model)

    # ëª¨ë¸ ì…ë ¥ í”¼ì²˜ ê¸°ì¤€
    model_features = predictor.model.get_booster().feature_names

    # One-hot ì¸ì½”ë”©ë˜ì–´ ìˆëŠ” ë°ì´í„°ë¥¼ ë³µì›í•˜ëŠ” í•¨ìˆ˜
    def reverse_one_hot_columns(df_encoded):
        reverse_map = {
            "PreferredLoginDevice": "ì„ í˜¸ ë¡œê·¸ì¸ ê¸°ê¸°",
            "PreferredPaymentMode": "ì„ í˜¸ ê²°ì œ ë°©ì‹",
            "Gender": "ì„±ë³„",
            "PreferedOrderCat": "ì„ í˜¸ ì£¼ë¬¸ ì¹´í…Œê³ ë¦¬",
            "MaritalStatus": "ê²°í˜¼ ì—¬ë¶€"
        }

        recovered = pd.DataFrame()

        for prefix_en, label_kr in reverse_map.items():
            matched = df_encoded.filter(like=prefix_en + "_")
            recovered[label_kr] = matched.idxmax(axis=1).str.replace(prefix_en + "_", "")

        numeric_features = [
            'Tenure', 'CityTier', 'WarehouseToHome', 'HourSpendOnApp',
            'NumberOfDeviceRegistered', 'SatisfactionScore', 'NumberOfAddress',
            'Complain', 'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount',
            'DaySinceLastOrder', 'CashbackAmount'
        ]
        numeric_labels = [
            "ì´ìš© ê¸°ê°„", "ê±°ì£¼ ë„ì‹œ ë“±ê¸‰", "ì°½ê³ -ì§‘ ê±°ë¦¬", "ì•± ì‚¬ìš© ì‹œê°„",
            "ë“±ë¡ëœ ê¸°ê¸° ìˆ˜", "ë§Œì¡±ë„ ì ìˆ˜", "ë°°ì†¡ì§€ ë“±ë¡ ìˆ˜",
            "ë¶ˆë§Œ ì œê¸° ì—¬ë¶€", "ì£¼ë¬¸ê¸ˆì•¡ ìƒìŠ¹ë¥ ", "ì¿ í° ì‚¬ìš© íšŸìˆ˜", "ì£¼ë¬¸ íšŸìˆ˜",
            "ë§ˆì§€ë§‰ ì£¼ë¬¸ í›„ ê²½ê³¼ì¼", "ìºì‹œë°± ê¸ˆì•¡"
        ]
        for en, kr in zip(numeric_features, numeric_labels):
            if en in df_encoded.columns:
                recovered[kr] = df_encoded[en]

        return recovered[numeric_labels + list(reverse_map.values())]

    # ëª¨ë¸ ì…ë ¥ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ í›„ ì¸ì½”ë”©
    df_input = df.copy()
    df_encoded = pd.get_dummies(df_input)

    for col in model_features:
        if col not in df_encoded.columns:
            df_encoded[col] = 0
    df_encoded = df_encoded[model_features]

    # âœ… ê³ ê° ID ìƒì„±
    df["ê³ ê°ID"] = [str(uuid.uuid4())[:8] for _ in range(len(df))]

    # âœ… ì˜ˆì¸¡ ìˆ˜í–‰
    _, y_proba = predictor.predict(df_encoded)
    df["ì´íƒˆí™•ë¥ "] = y_proba

    # âœ… ìœ„í—˜êµ° ë¶„ë¥˜
    df["ìœ„í—˜êµ°"] = df["ì´íƒˆí™•ë¥ "].apply(classify_risk)

    # âœ… í™•ì¸ ì¶œë ¥
    st.success(f"âœ… ì´ {len(df)}ëª…ì˜ ê³ ê°ì—ê²Œ IDë¥¼ ë¶€ì—¬í•˜ê³  ì´íƒˆ ìœ„í—˜ë„ë¥¼ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤.")

    # âœ… ìœ„í—˜êµ°ë³„ ê³ ê° ID í‘œì‹œ
    st.subheader("ğŸ“Œ ìœ„í—˜êµ°ë³„ ê³ ê° ID (ìƒìœ„ 10ê°œ)")
    for group in ["ì´ˆê³ ìœ„í—˜êµ°", "ê³ ìœ„í—˜êµ°", "ì£¼ì˜ë‹¨ê³„", "ê´€ì°°ë‹¨ê³„"]:
        st.markdown(f"**{group}**")
        top_ids = df[df["ìœ„í—˜êµ°"] == group].nlargest(10, "ì´íƒˆí™•ë¥ ")["ê³ ê°ID"].tolist()
        st.write(top_ids)
