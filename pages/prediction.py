import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from components.header import show_header
from components.animations import add_page_transition
from models.churn_model import ChurnPredictor

# ìºì‹œëœ ëª¨ë¸ ë¡œë”©
@st.cache_resource
def get_predictor():
    return ChurnPredictor()

# ê²Œì´ì§€ ì°¨íŠ¸ ìƒì„±
def create_churn_gauge(value: float) -> go.Figure:
    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=value * 100,
        title={"text": "ì´íƒˆ ê°€ëŠ¥ì„± (%)"},
        gauge={
            'axis': {'range': [0, 100]},
            'steps': [
                {'range': [0, 30], 'color': 'green'},
                {'range': [30, 70], 'color': 'yellow'},
                {'range': [70, 100], 'color': 'red'}
            ],
            'bar': {'color': 'darkblue'},
            'threshold': {'line': {'color': 'red', 'width': 4}, 'value': value * 100}
        }
    ))
    fig.update_layout(height=300, margin=dict(l=20, r=20, t=50, b=20))
    return fig

def show():
    # ì• ë‹ˆë©”ì´ì…˜ ì ìš©
    add_page_transition()

    # í—¤ë” í‘œì‹œ
    show_header()
    
    # ì•± ì‹œì‘
    st.title("ê³ ê° ì´íƒˆ ì˜ˆì¸¡")
    
    # ëª¨ë¸ íŠ¹ì„± í™•ì¸ (ë””ë²„ê·¸ìš©)
    with st.expander("ëª¨ë¸ íŠ¹ì„± í™•ì¸"):
        predictor = ChurnPredictor()
        if predictor.model is not None and hasattr(predictor.model, 'feature_names_in_'):
            st.write("### ëª¨ë¸ì´ ì‚¬ìš©í•˜ëŠ” íŠ¹ì„± ì´ë¦„ ëª©ë¡")
            feature_names = predictor.model.feature_names_in_
            
            # ì›í•«ì¸ì½”ë”©ëœ íŠ¹ì„± ê·¸ë£¹ ë¶„ì„
            encoded_features = predictor.get_onehot_encoded_features()
            
            # ì›í•«ì¸ì½”ë”©ëœ íŠ¹ì„± ê·¸ë£¹ í‘œì‹œ
            st.write("### ì›í•«ì¸ì½”ë”© ëœ íŠ¹ì„± ê·¸ë£¹")
            if encoded_features:
                total_encoded = sum(len(cols) for cols in encoded_features.values())
                st.write(f"ì›ë³¸ ë³€ìˆ˜ {len(encoded_features)}ê°œê°€ ì›í•«ì¸ì½”ë”©ë˜ì–´ ì´ {total_encoded}ê°œ ë³€ìˆ˜ë¡œ í™•ì¥ë¨")
                
                for prefix, columns in encoded_features.items():
                    with st.expander(f"{prefix} â†’ {len(columns)}ê°œ ë³€ìˆ˜"):
                        # ì˜ˆìƒë˜ëŠ” ì›ë³¸ ê°’ ì¶”ì¶œ (ì ‘ë‘ì‚¬ ì œê±°)
                        original_values = [col.replace(f"{prefix}_", "") for col in columns]
                        st.write("ì˜ˆìƒë˜ëŠ” ì›ë³¸ ê°’ë“¤:", ", ".join(sorted(original_values)))
                        st.write("ì›í•«ì¸ì½”ë”©ëœ ì»¬ëŸ¼ë“¤:", sorted(columns))
            else:
                st.warning("ì›í•«ì¸ì½”ë”©ëœ íŠ¹ì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì „ì²´ íŠ¹ì„± ëª©ë¡
            st.write("### ì „ì²´ íŠ¹ì„± ëª©ë¡")
            non_encoded = [f for f in sorted(feature_names) if not any(f in cols for cols in encoded_features.values())]
            
            col1, col2 = st.columns(2)
            with col1:
                st.write("ì›í•«ì¸ì½”ë”© ë˜ì§€ ì•Šì€ íŠ¹ì„±:")
                st.write(non_encoded)
            
            with col2:
                st.write("íŠ¹ì„± ìˆ˜ ìš”ì•½:")
                st.write(f"- ì´ íŠ¹ì„± ìˆ˜: {len(feature_names)}")
                st.write(f"- ì›í•«ì¸ì½”ë”© íŠ¹ì„± ìˆ˜: {total_encoded if encoded_features else 0}")
                st.write(f"- ì¼ë°˜ íŠ¹ì„± ìˆ˜: {len(non_encoded)}")
        else:
            st.error("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ê±°ë‚˜ feature_names_in_ ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    st.write("ê³ ê° ì •ë³´ë¥¼ ì…ë ¥í•˜ì—¬ ì´íƒˆ ê°€ëŠ¥ì„±ì„ ì˜ˆì¸¡í•´ë³´ì„¸ìš”.")

    # ì…ë ¥ ì»¬ëŸ¼ ì •ì˜ (+ CustomerID ì¶”ê°€, Churn ì œì™¸)
    columns = [
        'CustomerID',                  # ê³ ê° ID (ì¶”ê°€)
        'Tenure',                      # ê±°ë˜ê¸°ê°„
        'PreferredLoginDevice',        # ì„ í˜¸ ë¡œê·¸ì¸ ê¸°ê¸°
        'CityTier',                    # ë„ì‹œ ë“±ê¸‰
        'WarehouseToHome',             # ì°½ê³ ì—ì„œ ì§‘ê¹Œì§€ ê±°ë¦¬
        'PreferredPaymentMode',        # ì„ í˜¸ ê²°ì œ ë°©ì‹
        'Gender',                      # ì„±ë³„
        'HourSpendOnApp',              # ì•± ì‚¬ìš© ì‹œê°„
        'NumberOfDeviceRegistered',    # ë“±ë¡ëœ ê¸°ê¸° ìˆ˜
        'PreferedOrderCat',            # ì„ í˜¸ ì£¼ë¬¸ ì¹´í…Œê³ ë¦¬
        'SatisfactionScore',           # ë§Œì¡±ë„ ì ìˆ˜
        'MaritalStatus',               # ê²°í˜¼ ìƒíƒœ
        'NumberOfAddress',             # ì£¼ì†Œ ê°œìˆ˜
        'Complain',                    # ë¶ˆë§Œ ì œê¸° ì—¬ë¶€
        'OrderAmountHikeFromlastYear', # ì‘ë…„ ëŒ€ë¹„ ì£¼ë¬¸ ê¸ˆì•¡ ì¦ê°€ìœ¨
        'CouponUsed',                  # ì¿ í° ì‚¬ìš© íšŸìˆ˜
        'OrderCount',                  # ì£¼ë¬¸ íšŸìˆ˜
        'DaySinceLastOrder',           # ë§ˆì§€ë§‰ ì£¼ë¬¸ í›„ ê²½ê³¼ì¼
        'CashbackAmount'               # ìºì‹œë°± ê¸ˆì•¡
    ]

    # í•„ìˆ˜ ì…ë ¥ í•„ë“œ ì§€ì • (ë‚˜ë¨¸ì§€ëŠ” ì„ íƒ ì‚¬í•­)
    required_columns = [
        'CustomerID',              # ê³ ê° ID (í•„ìˆ˜ ì¶”ê°€)
        'Tenure',                  # ê±°ë˜ê¸°ê°„
        'SatisfactionScore',       # ë§Œì¡±ë„ ì ìˆ˜
        'OrderCount',              # ì£¼ë¬¸ íšŸìˆ˜
        'HourSpendOnApp',          # ì•± ì‚¬ìš© ì‹œê°„
        'DaySinceLastOrder'        # ë§ˆì§€ë§‰ ì£¼ë¬¸ í›„ ê²½ê³¼ì¼
    ]

    # ì»¬ëŸ¼ë³„ í•œê¸€ ì´ë¦„ ë§¤í•‘
    column_korean_names = {
        'CustomerID': 'ê³ ê° ID',
        'Tenure': 'ê±°ë˜ê¸°ê°„ (ê°œì›”)',
        'PreferredLoginDevice': 'ì„ í˜¸ ë¡œê·¸ì¸ ê¸°ê¸°',
        'CityTier': 'ë„ì‹œ ë“±ê¸‰',
        'WarehouseToHome': 'ì°½ê³ -ì§‘ ê±°ë¦¬ (km)',
        'PreferredPaymentMode': 'ì„ í˜¸ ê²°ì œ ë°©ì‹',
        'Gender': 'ì„±ë³„',
        'HourSpendOnApp': 'ì•± ì‚¬ìš© ì‹œê°„ (ì‹œê°„)',
        'NumberOfDeviceRegistered': 'ë“±ë¡ëœ ê¸°ê¸° ìˆ˜',
        'PreferedOrderCat': 'ì„ í˜¸ ì£¼ë¬¸ ì¹´í…Œê³ ë¦¬',
        'SatisfactionScore': 'ë§Œì¡±ë„ ì ìˆ˜ (1-5)',
        'MaritalStatus': 'ê²°í˜¼ ìƒíƒœ',
        'NumberOfAddress': 'ì£¼ì†Œ ê°œìˆ˜',
        'Complain': 'ë¶ˆë§Œ ì œê¸° ì—¬ë¶€',
        'OrderAmountHikeFromlastYear': 'ì‘ë…„ ëŒ€ë¹„ ì£¼ë¬¸ ê¸ˆì•¡ ì¦ê°€ìœ¨ (%)',
        'CouponUsed': 'ì¿ í° ì‚¬ìš© íšŸìˆ˜',
        'OrderCount': 'ì£¼ë¬¸ íšŸìˆ˜',
        'DaySinceLastOrder': 'ë§ˆì§€ë§‰ ì£¼ë¬¸ í›„ ê²½ê³¼ì¼',
        'CashbackAmount': 'ìºì‹œë°± ê¸ˆì•¡ (ì›)'
    }

    # íƒ€ì…ê³¼ ì„ íƒì§€ ë§¤í•‘
    column_types = {
        'CustomerID': 'text',       # ê³ ê° IDëŠ” í…ìŠ¤íŠ¸ íƒ€ì…
        'Tenure': 'number',
        'PreferredLoginDevice': 'select',
        'CityTier': 'number',
        'WarehouseToHome': 'number',
        'PreferredPaymentMode': 'select',
        'Gender': 'select',
        'HourSpendOnApp': 'number',
        'NumberOfDeviceRegistered': 'number',
        'PreferedOrderCat': 'select',
        'SatisfactionScore': 'number',
        'MaritalStatus': 'select',
        'NumberOfAddress': 'number',
        'Complain': 'select',
        'OrderAmountHikeFromlastYear': 'number',
        'CouponUsed': 'number',
        'OrderCount': 'number',
        'DaySinceLastOrder': 'number',
        'CashbackAmount': 'number'
    }

    # ì„ íƒ í•­ëª© ë§¤í•‘
    select_options = {
        'PreferredLoginDevice': ['Mobile', 'Desktop', 'Tablet'],
        'PreferredPaymentMode': ['Credit Card', 'Debit Card', 'UPI', 'Cash on Delivery'],
        'Gender': ['Male', 'Female'],
        'PreferedOrderCat': ['Electronics', 'Fashion', 'Grocery', 'Home'],
        'MaritalStatus': ['Single', 'Married', 'Divorced'],
        'Complain': ['ì˜ˆ', 'ì•„ë‹ˆì˜¤']
    }

    # ê¸°ë³¸ê°’ ë§¤í•‘
    default_values = {
        'CustomerID': 'CUST-' + ''.join(['0' + str(np.random.randint(10000, 100000))]),  # ëœë¤ ê³ ê° ID 
        'Tenure': 12,
        'PreferredLoginDevice': 'Mobile',
        'CityTier': 1,
        'WarehouseToHome': 20,
        'PreferredPaymentMode': 'Credit Card',
        'Gender': 'Male',
        'HourSpendOnApp': 3.0,
        'NumberOfDeviceRegistered': 2,
        'PreferedOrderCat': 'Electronics',
        'SatisfactionScore': 3,
        'MaritalStatus': 'Single',
        'NumberOfAddress': 2,
        'Complain': 'ì•„ë‹ˆì˜¤',
        'OrderAmountHikeFromlastYear': 15.0,
        'CouponUsed': 3,
        'OrderCount': 10,
        'DaySinceLastOrder': 15,
        'CashbackAmount': 150.0
    }

    # í•„ìˆ˜ ì…ë ¥ í•„ë“œ í‘œì‹œ
    st.markdown("""
    <style>
    .required-field::after {
        content: " *";
        color: red;
    }
    </style>
    """, unsafe_allow_html=True)

    st.markdown("**ì°¸ê³ :** ë¹¨ê°„ìƒ‰ ë³„í‘œ(\*) í‘œì‹œê°€ ìˆëŠ” í•„ë“œëŠ” í•„ìˆ˜ ì…ë ¥ ì‚¬í•­ì…ë‹ˆë‹¤.")

    # ì…ë ¥ê°’ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    input_data = {}

    # í•„ìˆ˜ ì…ë ¥ í•„ë“œ ê²€ì¦ìš© ë³€ìˆ˜
    required_fields_filled = {col: False for col in required_columns}

    # í•„ë“œ ì¹´í…Œê³ ë¦¬ë¡œ ê·¸ë£¹í™” (í•„ìˆ˜/ì„ íƒ)
    required_fields = []
    optional_fields = []

    for col in columns:
        if col in required_columns:
            required_fields.append(col)
        else:
            optional_fields.append(col)

    # íƒ­ ìƒì„±
    tab1, tab2 = st.tabs(["í•„ìˆ˜ ì…ë ¥ í•„ë“œ", "ì„ íƒ ì…ë ¥ í•„ë“œ"])

    with tab1:
        # í•„ìˆ˜ ì…ë ¥ í•„ë“œ ê·¸ë¦¬ë“œ
        st.markdown("### í•„ìˆ˜ ì…ë ¥ í•„ë“œ")
        
        # ê·¸ë¦¬ë“œ ì—´ ìˆ˜ ê³„ì‚° (ìµœëŒ€ 3ê°œ ì»¬ëŸ¼)
        req_cols = 3
        req_rows = (len(required_fields) + req_cols - 1) // req_cols
        
        for row in range(req_rows):
            cols = st.columns(req_cols)
            for col in range(req_cols):
                idx = row * req_cols + col
                
                if idx < len(required_fields):
                    column = required_fields[idx]
                    korean_name = column_korean_names.get(column, column)
                    # í•„ìˆ˜ ì…ë ¥ í‘œì‹œ ì¶”ê°€
                    label = f"<div class='required-field'>{korean_name}</div>"
                    col_type = column_types.get(column, 'text')
                    
                    with cols[col]:
                        st.markdown(label, unsafe_allow_html=True)
                        
                        # ì»¬ëŸ¼ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ì…ë ¥ ìœ„ì ¯ ìƒì„±
                        if col_type == 'text':
                            # í…ìŠ¤íŠ¸ íƒ€ì… ì…ë ¥ (ê³ ê° ID ë“±)
                            value = st.text_input(
                                "",  # ë ˆì´ë¸”ì€ ìœ„ì—ì„œ ì´ë¯¸ í‘œì‹œ
                                value=default_values.get(column, ""),
                                key=f"input_{column}"
                            )
                            input_data[column] = value
                            if value and column in required_columns:
                                required_fields_filled[column] = True
                            
                        elif col_type == 'number':
                            # ìˆ«ì íƒ€ì… ì…ë ¥
                            min_val = 0 if column in ['Tenure', 'CityTier', 'WarehouseToHome', 'HourSpendOnApp', 
                                                   'NumberOfDeviceRegistered', 'SatisfactionScore', 'NumberOfAddress',
                                                   'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount', 
                                                   'DaySinceLastOrder', 'CashbackAmount'] else 0.0
                            
                            # íŠ¹ë³„ ë²”ìœ„ ì„¤ì •
                            if column == 'SatisfactionScore':
                                min_val, max_val = 1, 5
                            else:
                                max_val = None
                            
                            if column in ['HourSpendOnApp', 'OrderAmountHikeFromlastYear', 'CashbackAmount']:
                                # ì†Œìˆ˜ì ì´ í•„ìš”í•œ ê²½ìš°
                                value = st.number_input(
                                    "",  # ë ˆì´ë¸”ì€ ìœ„ì—ì„œ ì´ë¯¸ í‘œì‹œ
                                    min_value=float(min_val) if min_val is not None else None,
                                    max_value=float(max_val) if max_val is not None else None,
                                    value=float(default_values.get(column, 0.0)),
                                    step=0.1,
                                    key=f"input_{column}"
                                )
                                input_data[column] = value
                                if value > 0 or column not in required_columns:
                                    required_fields_filled[column] = True
                            else:
                                # ì •ìˆ˜ ì…ë ¥
                                value = st.number_input(
                                    "",  # ë ˆì´ë¸”ì€ ìœ„ì—ì„œ ì´ë¯¸ í‘œì‹œ
                                    min_value=int(min_val) if min_val is not None else None,
                                    max_value=int(max_val) if max_val is not None else None,
                                    value=int(default_values.get(column, 0)),
                                    step=1,
                                    key=f"input_{column}"
                                )
                                input_data[column] = value
                                if value > 0 or column not in required_columns:
                                    required_fields_filled[column] = True
                        
                        elif col_type == 'select':
                            # ì„ íƒí˜• ì…ë ¥
                            options = select_options.get(column, [])
                            default_idx = options.index(default_values.get(column)) if default_values.get(column) in options else 0
                            
                            if column == 'Complain':
                                # ì˜ˆ/ì•„ë‹ˆì˜¤ ì„ íƒì˜ ê²½ìš° booleanìœ¼ë¡œ ë³€í™˜
                                selected = st.selectbox(
                                    "",  # ë ˆì´ë¸”ì€ ìœ„ì—ì„œ ì´ë¯¸ í‘œì‹œ
                                    options,
                                    index=0 if default_values.get(column) == 'ì•„ë‹ˆì˜¤' else 1,
                                    key=f"input_{column}"
                                )
                                input_data[column] = selected  # ë¬¸ìì—´ 'ì˜ˆ'/'ì•„ë‹ˆì˜¤' ê·¸ëŒ€ë¡œ ìœ ì§€
                            else:
                                input_data[column] = st.selectbox(
                                    "",  # ë ˆì´ë¸”ì€ ìœ„ì—ì„œ ì´ë¯¸ í‘œì‹œ
                                    options,
                                    index=default_idx,
                                    key=f"input_{column}"
                                )
                            
                            # ì„ íƒí˜• í•„ë“œëŠ” í•­ìƒ ê°’ì´ ìˆìœ¼ë¯€ë¡œ í•„ìˆ˜ í•„ë“œ ì¶©ì¡± ì²˜ë¦¬
                            if column in required_columns:
                                required_fields_filled[column] = True

    with tab2:
        # ì„ íƒ ì…ë ¥ í•„ë“œ ê·¸ë¦¬ë“œ
        st.markdown("### ì„ íƒ ì…ë ¥ í•„ë“œ")
        
        # ê·¸ë¦¬ë“œ ì—´ ìˆ˜ ê³„ì‚° (ìµœëŒ€ 3ê°œ ì»¬ëŸ¼)
        opt_cols = 3
        opt_rows = (len(optional_fields) + opt_cols - 1) // opt_cols
        
        for row in range(opt_rows):
            cols = st.columns(opt_cols)
            for col in range(opt_cols):
                idx = row * opt_cols + col
                
                if idx < len(optional_fields):
                    column = optional_fields[idx]
                    korean_name = column_korean_names.get(column, column)
                    col_type = column_types.get(column, 'text')
                    
                    with cols[col]:
                        # ì»¬ëŸ¼ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ì…ë ¥ ìœ„ì ¯ ìƒì„±
                        if col_type == 'text':
                            # í…ìŠ¤íŠ¸ íƒ€ì… ì…ë ¥
                            input_data[column] = st.text_input(
                                korean_name,
                                value=default_values.get(column, ""),
                                key=f"input_{column}"
                            )
                        
                        elif col_type == 'number':
                            # ìˆ«ì íƒ€ì… ì…ë ¥
                            min_val = 0 if column in ['Tenure', 'CityTier', 'WarehouseToHome', 'HourSpendOnApp', 
                                                   'NumberOfDeviceRegistered', 'SatisfactionScore', 'NumberOfAddress',
                                                   'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount', 
                                                   'DaySinceLastOrder', 'CashbackAmount'] else 0.0
                            
                            # íŠ¹ë³„ ë²”ìœ„ ì„¤ì •
                            if column == 'SatisfactionScore':
                                min_val, max_val = 1, 5
                            else:
                                max_val = None
                            
                            if column in ['HourSpendOnApp', 'OrderAmountHikeFromlastYear', 'CashbackAmount']:
                                # ì†Œìˆ˜ì ì´ í•„ìš”í•œ ê²½ìš°
                                input_data[column] = st.number_input(
                                    korean_name,
                                    min_value=float(min_val) if min_val is not None else None,
                                    max_value=float(max_val) if max_val is not None else None,
                                    value=float(default_values.get(column, 0.0)),
                                    step=0.1,
                                    key=f"input_{column}"
                                )
                            else:
                                # ì •ìˆ˜ ì…ë ¥
                                input_data[column] = st.number_input(
                                    korean_name,
                                    min_value=int(min_val) if min_val is not None else None,
                                    max_value=int(max_val) if max_val is not None else None,
                                    value=int(default_values.get(column, 0)),
                                    step=1,
                                    key=f"input_{column}"
                                )
                        
                        elif col_type == 'select':
                            # ì„ íƒí˜• ì…ë ¥
                            options = select_options.get(column, [])
                            default_idx = options.index(default_values.get(column)) if default_values.get(column) in options else 0
                            
                            if column == 'Complain':
                                # ì˜ˆ/ì•„ë‹ˆì˜¤ ì„ íƒì˜ ê²½ìš° booleanìœ¼ë¡œ ë³€í™˜
                                selected = st.selectbox(
                                    korean_name,
                                    options,
                                    index=0 if default_values.get(column) == 'ì•„ë‹ˆì˜¤' else 1,
                                    key=f"input_{column}"
                                )
                                input_data[column] = selected  # ë¬¸ìì—´ 'ì˜ˆ'/'ì•„ë‹ˆì˜¤' ê·¸ëŒ€ë¡œ ìœ ì§€
                            else:
                                input_data[column] = st.selectbox(
                                    korean_name,
                                    options,
                                    index=default_idx,
                                    key=f"input_{column}"
                                )

    # ì˜ˆì¸¡ ë²„íŠ¼
    st.markdown("---")
    col1, col2, col3 = st.columns([1, 1, 1])

    with col2:
        predict_button = st.button("ì´íƒˆ ì˜ˆì¸¡í•˜ê¸°", use_container_width=True, type="primary")

    # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
    if predict_button:
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        all_required_filled = all(required_fields_filled.values())
        
        if not all_required_filled:
            # í•„ìˆ˜ ì…ë ¥ í•„ë“œ ë¯¸ì…ë ¥ ì‹œ ê²½ê³  í‘œì‹œ
            missing_fields = [column_korean_names.get(col, col) for col, filled in required_fields_filled.items() if not filled]
            st.error(f"ë‹¤ìŒ í•„ìˆ˜ ì…ë ¥ í•­ëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: {', '.join(missing_fields)}")
        else:
            # ë¡œë”© í‘œì‹œ
            with st.spinner("ì˜ˆì¸¡ ì¤‘..."):
                try:
                    # ì…ë ¥ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                    input_df = pd.DataFrame([input_data])
                    
                    # ê³ ê° ID í‘œì‹œ
                    st.markdown(f"### ê³ ê° ID: {input_data['CustomerID']}")
                    
                    # ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡
                    predictor = ChurnPredictor()
                    
                    _, y_proba = predictor.predict(input_df)
                    
                    prob_value = y_proba[0]  # ì´íƒˆ í™•ë¥ 

                    # ê²°ê³¼ í‘œì‹œ
                    st.markdown("---")
                    st.subheader("ì˜ˆì¸¡ ê²°ê³¼")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # ì´íƒˆ í™•ë¥  ê²Œì´ì§€
                        st.plotly_chart(
                            create_churn_gauge(prob_value),
                            use_container_width=True
                        )
                    
                    with col2:
                        # ìœ„í—˜ë„ ìˆ˜ì¤€
                        if prob_value < 0.3:
                            risk_level = "low"
                            risk_text = "ë‚®ìŒ"
                            risk_color = "#4CAF50"
                            action_text = "ì •ê¸°ì ì¸ ë§ˆì¼€íŒ… ì´ë©”ì¼ì„ ë³´ë‚´ê³  ì¼ë°˜ì ì¸ ê³ ê° ê´€ë¦¬ë¥¼ ìœ ì§€í•˜ì„¸ìš”."
                        elif prob_value < 0.7:
                            risk_level = "medium"
                            risk_text = "ì¤‘ê°„"
                            risk_color = "#FFC107"
                            action_text = "íŠ¹ë³„ í• ì¸ì´ë‚˜ ê°œì¸í™”ëœ ì œì•ˆì„ í†µí•´ ì°¸ì—¬ë„ë¥¼ ë†’ì´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
                        else:
                            risk_level = "high"
                            risk_text = "ë†’ìŒ"
                            risk_color = "#F44336"
                            action_text = "ì¦‰ê°ì ì¸ ê³ ê° ì‘ëŒ€ì™€ íŠ¹ë³„ í˜œíƒ ì œê³µì´ í•„ìš”í•©ë‹ˆë‹¤."
                        
                        # ê²°ê³¼ ìš”ì•½
                        st.markdown(f"""
                        ### ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½
                        - **ì´íƒˆ í™•ë¥ **: {prob_value:.2%}
                        - **ìœ„í—˜ë„**: <span style='color:{risk_color};font-weight:bold'>{risk_text}</span>
                        
                        ### ê¶Œì¥ ì¡°ì¹˜
                        {action_text}
                        """, unsafe_allow_html=True)
                    
                    # ì£¼ìš” ì˜í–¥ ìš”ì¸
                    st.subheader("ì£¼ìš” ì˜í–¥ ìš”ì¸")
                    
                    # ì˜í–¥ ìš”ì¸ ê³„ì‚° (ëª¨ë¸ ê¸°ë°˜)
                    feature_importance = predictor.get_feature_importance()
                    
                    # NumPy ë°°ì—´ì— ëŒ€í•œ ì§ì ‘ ë¶ˆë¦¬ì–¸ í‰ê°€ ë°©ì§€
                    is_valid_dict = isinstance(feature_importance, dict)
                    
                    if is_valid_dict:
                        # íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                        factors = [
                            {"name": column_korean_names.get(feature, feature), 
                             "value": float(importance), 
                             "weight": 1.0,  # ì´ë¯¸ ì¤‘ìš”ë„ì— ê°€ì¤‘ì¹˜ê°€ ë°˜ì˜ë˜ì–´ ìˆìŒ
                             "description": f"{column_korean_names.get(feature, feature)}ì´(ê°€) ì´íƒˆ í™•ë¥ ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤."}
                            for feature, importance in feature_importance.items()
                        ]
                        
                        # ì¤‘ìš”ë„ë¡œ ì •ë ¬
                        factors.sort(key=lambda x: x["value"], reverse=True)
                        
                        # ìƒìœ„ 3ê°œ ìš”ì¸
                        top_factors = factors[:3]
                    else:
                        # ëª¨ë¸ì—ì„œ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ì–»ì§€ ëª»í•œ ê²½ìš°: ì…ë ¥ê°’ ê¸°ë°˜ ê³„ì‚°
                        # í•„ìš”í•œ ê³„ìˆ˜ ë‹¤ì‹œ ê³„ì‚°
                        tenure_factor = 1 - min(input_data.get('Tenure', 0), 60) / 60
                        app_factor = 1 - min(input_data.get('HourSpendOnApp', 0), 10) / 10
                        satisfaction_factor = 1 - input_data.get('SatisfactionScore', 3) / 5
                        order_factor = 1 - min(input_data.get('OrderCount', 0), 50) / 50
                        dayslast_factor = min(input_data.get('DaySinceLastOrder', 0), 90) / 90
                        
                        factors = [
                            {"name": "ê±°ë˜ê¸°ê°„", "value": tenure_factor, "weight": 0.2, "description": "ê±°ë˜ê¸°ê°„ì´ ê¸¸ìˆ˜ë¡ ì´íƒˆ í™•ë¥ ì´ ë‚®ì•„ì§‘ë‹ˆë‹¤."},
                            {"name": "ì•± ì‚¬ìš© ì‹œê°„", "value": app_factor, "weight": 0.2, "description": "ì•± ì‚¬ìš© ì‹œê°„ì´ ê¸¸ìˆ˜ë¡ ì´íƒˆ í™•ë¥ ì´ ë‚®ì•„ì§‘ë‹ˆë‹¤."},
                            {"name": "ë§Œì¡±ë„ ì ìˆ˜", "value": satisfaction_factor, "weight": 0.3, "description": "ë§Œì¡±ë„ê°€ ë†’ì„ìˆ˜ë¡ ì´íƒˆ í™•ë¥ ì´ ë‚®ì•„ì§‘ë‹ˆë‹¤."},
                            {"name": "ì£¼ë¬¸ íšŸìˆ˜", "value": order_factor, "weight": 0.1, "description": "ì£¼ë¬¸ íšŸìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ì´íƒˆ í™•ë¥ ì´ ë‚®ì•„ì§‘ë‹ˆë‹¤."},
                            {"name": "ë§ˆì§€ë§‰ ì£¼ë¬¸ í›„ ê²½ê³¼ì¼", "value": dayslast_factor, "weight": 0.2, "description": "ë§ˆì§€ë§‰ ì£¼ë¬¸ ì´í›„ ì‹œê°„ì´ ê¸¸ìˆ˜ë¡ ì´íƒˆ í™•ë¥ ì´ ë†’ì•„ì§‘ë‹ˆë‹¤."}
                        ]
                        factors.sort(key=lambda x: x["value"] * x["weight"], reverse=True)
                        top_factors = factors[:3]
                    
                    # ìš”ì¸ë³„ ê°€ì¤‘ ì˜í–¥ë ¥ ê³„ì‚°
                    weighted_factors = [(f["name"], f["value"] * f["weight"], f["description"]) for f in top_factors]
                    
                    # ë§‰ëŒ€ ê·¸ë˜í”„ ë°ì´í„°
                    factor_df = pd.DataFrame({
                        'ìš”ì¸': [f[0] for f in weighted_factors],
                        'ì˜í–¥ë ¥': [f[1] for f in weighted_factors]
                    })
                    
                    # ë§‰ëŒ€ ê·¸ë˜í”„ í‘œì‹œ
                    st.bar_chart(factor_df, x='ìš”ì¸', y='ì˜í–¥ë ¥')
                    
                    # ìš”ì¸ë³„ ì„¤ëª…
                    for name, impact, desc in weighted_factors:
                        st.markdown(f"**{name}**: {desc}")
                    
                    # ë””ë²„ê·¸ ì •ë³´ ì„¹ì…˜ ì¶”ê°€
                    with st.expander("ğŸ”§ ë””ë²„ê·¸ ì •ë³´"):
                        debug_tabs = st.tabs(["ì…ë ¥ ë°ì´í„°", "ëª¨ë¸ ì •ë³´", "ì˜ˆì¸¡ ê³¼ì •", "ë¡œê·¸"])
                        
                        with debug_tabs[0]:
                            st.write("### ì›ë³¸ ì…ë ¥ ë°ì´í„°")
                            st.dataframe(input_df)
                            
                            # ì „ì²˜ë¦¬ ê³¼ì • í™•ì¸ì„ ìœ„í•´ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì§ì ‘ í˜¸ì¶œ
                            processed_df = predictor._preprocess_data(input_df)
                            st.write("### ì „ì²˜ë¦¬ í›„ ë°ì´í„° (ì›í•«ì¸ì½”ë”© ì ìš©)")
                            st.dataframe(processed_df)
                            
                            # ì›í•«ì¸ì½”ë”© ì •ë³´ í‘œì‹œ
                            encoded_features = predictor.get_onehot_encoded_features()
                            
                            st.write("### ì›í•«ì¸ì½”ë”© ë³€í™˜ ì •ë³´")
                            if encoded_features:
                                # ë²”ì£¼í˜• ë³€ìˆ˜ë³„ë¡œ ì›ë³¸ ê°’ê³¼ ë³€í™˜ëœ ê°’ í‘œì‹œ
                                for prefix, columns in encoded_features.items():
                                    with st.expander(f"{prefix} ë³€ìˆ˜ì˜ ì›í•«ì¸ì½”ë”©"):
                                        # ì…ë ¥ ë°ì´í„°ì—ì„œ í•´ë‹¹ ë³€ìˆ˜ ê°’ í™•ì¸
                                        if prefix in input_df.columns:
                                            original_value = input_df[prefix].iloc[0]
                                            st.write(f"ì…ë ¥ê°’: {original_value}")
                                            
                                            # ë³€í™˜ í›„ ë°ì´í„°ì—ì„œ í•´ë‹¹ ì›í•«ì¸ì½”ë”© ì»¬ëŸ¼ë“¤ ê°’ í™•ì¸
                                            encoded_values = {}
                                            for col in columns:
                                                if col in processed_df.columns:
                                                    encoded_values[col] = processed_df[col].iloc[0]
                                            
                                            encoded_df = pd.DataFrame([encoded_values])
                                            st.write("ì›í•«ì¸ì½”ë”© ê²°ê³¼:")
                                            st.dataframe(encoded_df.T)  # ì „ì¹˜í•˜ì—¬ ë³´ê¸° ì¢‹ê²Œ í‘œì‹œ
                            
                            st.write("### ì»¬ëŸ¼ ë³€í™˜ ì •ë³´")
                            st.write(f"- ì›ë³¸ ì…ë ¥ ì»¬ëŸ¼ ìˆ˜: {len(input_df.columns)}")
                            st.write(f"- ì „ì²˜ë¦¬ í›„ ì»¬ëŸ¼ ìˆ˜: {len(processed_df.columns)}")
                            st.write(f"- ì°¨ì´: {len(processed_df.columns) - len(input_df.columns)}ê°œ ì»¬ëŸ¼ ì¶”ê°€ë¨")
                            
                            if hasattr(predictor.model, 'feature_names_in_'):
                                expected_columns = set(predictor.model.feature_names_in_)
                                actual_columns = set(processed_df.columns)
                                
                                # ëª¨ë¸ê³¼ ì…ë ¥ ë°ì´í„°ì˜ ì»¬ëŸ¼ ì¼ì¹˜ ì—¬ë¶€ í™•ì¸
                                if expected_columns == actual_columns:
                                    st.success("âœ… ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” ì»¬ëŸ¼ê³¼ ì „ì²˜ë¦¬ í›„ ì»¬ëŸ¼ì´ ì •í™•íˆ ì¼ì¹˜í•©ë‹ˆë‹¤.")
                                else:
                                    st.error("âŒ ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” ì»¬ëŸ¼ê³¼ ì „ì²˜ë¦¬ í›„ ì»¬ëŸ¼ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                                    missing = expected_columns - actual_columns
                                    extra = actual_columns - expected_columns
                                    
                                    if missing:
                                        st.write("ëˆ„ë½ëœ ì»¬ëŸ¼:", missing)
                                    if extra:
                                        st.write("ì¶”ê°€ëœ ì»¬ëŸ¼:", extra)
                            
                            st.write("### JSON í˜•ì‹ ì…ë ¥ ë°ì´í„°")
                            st.json(input_data)
                        
                        with debug_tabs[1]:
                            st.write("### ëª¨ë¸ ì •ë³´")
                            st.write(f"**ëª¨ë¸ ê²½ë¡œ:** {predictor.model_path}")
                            st.write(f"**ëª¨ë¸ ë¡œë“œ ìƒíƒœ:** {'ì„±ê³µ' if predictor.model is not None else 'ì‹¤íŒ¨'}")
                            
                            # NumPy ë°°ì—´ ì§ì ‘ í‰ê°€ ë°©ì§€
                            has_cache = predictor.feature_importance_cache is not None
                            st.write(f"**íŠ¹ì„± ì¤‘ìš”ë„ ìºì‹œ:** {'ìˆìŒ' if has_cache else 'ì—†ìŒ'}")
                            
                            if hasattr(predictor.model, 'feature_importances_'):
                                st.write("### ëª¨ë¸ íŠ¹ì„± ì¤‘ìš”ë„")
                                feature_importances = predictor.model.feature_importances_
                                
                                # ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ì˜ ì»¬ëŸ¼ ê°€ì ¸ì˜¤ê¸°
                                processed_df = predictor._preprocess_data(input_df)
                                
                                # ì»¬ëŸ¼ê³¼ íŠ¹ì„± ì¤‘ìš”ë„ ê¸¸ì´ í™•ì¸ ë° ì¡°ì •
                                if len(feature_importances) == len(processed_df.columns):
                                    # ì»¬ëŸ¼ ìˆ˜ì™€ íŠ¹ì„± ì¤‘ìš”ë„ ìˆ˜ê°€ ì¼ì¹˜í•  ë•Œ
                                    importance_df = pd.DataFrame({
                                        'íŠ¹ì„±': processed_df.columns,
                                        'ì¤‘ìš”ë„': feature_importances
                                    })
                                    st.dataframe(importance_df.sort_values('ì¤‘ìš”ë„', ascending=False))
                                elif hasattr(predictor.model, 'feature_names_in_'):
                                    # ëª¨ë¸ì´ feature_names_in_ ì†ì„±ì„ ê°€ì§€ê³  ìˆì„ ë•Œ
                                    importance_df = pd.DataFrame({
                                        'íŠ¹ì„±': predictor.model.feature_names_in_,
                                        'ì¤‘ìš”ë„': feature_importances
                                    })
                                    st.dataframe(importance_df.sort_values('ì¤‘ìš”ë„', ascending=False))
                                else:
                                    # ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ì¸ë±ìŠ¤ë§Œ ì‚¬ìš©
                                    st.warning(f"íŠ¹ì„± ì¤‘ìš”ë„({len(feature_importances)})ì™€ ì…ë ¥ ì»¬ëŸ¼ ìˆ˜({len(processed_df.columns)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                                    importance_df = pd.DataFrame({
                                        'íŠ¹ì„± ì¸ë±ìŠ¤': range(len(feature_importances)),
                                        'ì¤‘ìš”ë„': feature_importances
                                    })
                                    st.dataframe(importance_df.sort_values('ì¤‘ìš”ë„', ascending=False))
                        
                        with debug_tabs[2]:
                            st.write("### ì˜ˆì¸¡ ê³¼ì •")
                            st.write(f"**ì´íƒˆ í™•ë¥  ê°’:** {prob_value}")
                            st.write(f"**ì´íƒˆ ìœ„í—˜ë„:** {risk_text}")
                            
                            # NumPy ë°°ì—´ ì§ì ‘ í‰ê°€ ë°©ì§€
                            is_dict_feature = isinstance(feature_importance, dict)
                            st.write(f"**íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚° ë°©ë²•:** {'ëª¨ë¸ ê¸°ë°˜' if is_dict_feature else 'ê¸°ë³¸ê°’ ê¸°ë°˜'}")
                            
                            st.write("### ëª¨ë“  ì˜í–¥ ìš”ì¸")
                            
                            # ì•ˆì „í•˜ê²Œ DataFrame ìƒì„±
                            try:
                                # ë°ì´í„°ê°€ ì¡´ì¬í•˜ê³  ëª¨ë“  í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                                if factors and all(key in factors[0] for key in ['name', 'value', 'weight', 'description']):
                                    # í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œí•˜ì—¬ DataFrame ìƒì„±
                                    factor_data = {
                                        'ìš”ì¸': [f.get('name', '') for f in factors],
                                        'ê°’': [f.get('value', 0) for f in factors],
                                        'ê°€ì¤‘ì¹˜': [f.get('weight', 0) for f in factors],
                                        'ì„¤ëª…': [f.get('description', '') for f in factors]
                                    }
                                    all_factors_df = pd.DataFrame(factor_data)
                                    st.dataframe(all_factors_df)
                                else:
                                    st.warning("ì˜í–¥ ìš”ì¸ ë°ì´í„°ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                    st.write(factors)  # ì›ë³¸ ë°ì´í„° í‘œì‹œ
                            except Exception as e:
                                st.error(f"ì˜í–¥ ìš”ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                                st.write("ì›ë³¸ ë°ì´í„°:", factors)
                        
                        with debug_tabs[3]:
                            st.write("### ë¡œê·¸ ì •ë³´")
                            st.code(f"""
# ëª¨ë¸ ë¡œë“œ ì‹œë„
model_path: {predictor.model_path}
model_loaded: {predictor.model is not None}

# ì…ë ¥ ë°ì´í„° ì²˜ë¦¬
input_rows: {len(input_df)}
input_columns: {len(input_df.columns)}

# ì˜ˆì¸¡ ìˆ˜í–‰
probability: {prob_value:.4f}
risk_level: {risk_level}
                            """)
                        
                except Exception as e:
                    st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    import traceback
                    st.write("ìƒì„¸ ì˜¤ë¥˜:")
                    st.code(traceback.format_exc())

# ë©”ì¸ í•¨ìˆ˜ í˜¸ì¶œì´ í•„ìš”í•˜ë©´ ì¶”ê°€
if __name__ == "__main__":
    show() 